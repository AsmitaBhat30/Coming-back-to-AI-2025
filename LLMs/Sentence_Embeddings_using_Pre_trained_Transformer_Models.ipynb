{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2cb9dd20fa748f092257e151de4a90d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_290ff546e4a64b9f9bb5d34a632cc02f",
              "IPY_MODEL_a418dd09edb1431d896f2470917d49cf",
              "IPY_MODEL_1f32d452e8ef4e0b8248d0771ff77051"
            ],
            "layout": "IPY_MODEL_10d137e231274e53a0f9314023af97bf"
          }
        },
        "290ff546e4a64b9f9bb5d34a632cc02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2eab3f38bb94f91bc64e2010da754dd",
            "placeholder": "​",
            "style": "IPY_MODEL_26e7e93b3ae8479b8bb0af8d88908b9c",
            "value": "Computing widget examples:   0%"
          }
        },
        "a418dd09edb1431d896f2470917d49cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddf8aae8a3184df49af0661013fc5b3e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbf7bbe9b87f48478bc878126e49cd76",
            "value": 1
          }
        },
        "1f32d452e8ef4e0b8248d0771ff77051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e27ef2f283349dcbc8680f95cfa6fa5",
            "placeholder": "​",
            "style": "IPY_MODEL_e88217e65b3d4c51a130a0b9fc662f7b",
            "value": " 0/1 [00:00&lt;?, ?example/s]"
          }
        },
        "10d137e231274e53a0f9314023af97bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "e2eab3f38bb94f91bc64e2010da754dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26e7e93b3ae8479b8bb0af8d88908b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddf8aae8a3184df49af0661013fc5b3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbf7bbe9b87f48478bc878126e49cd76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e27ef2f283349dcbc8680f95cfa6fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e88217e65b3d4c51a130a0b9fc662f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training an embedding model"
      ],
      "metadata": {
        "id": "_fQ-xO6-Woxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load MNLI dataset from GLUE\n",
        "# 0 = entailment, 1 = neutral, 2 = contradiction\n",
        "train_dataset = load_dataset('glue', 'mnli', split='train').select(range(50_000))\n",
        "\n",
        "train_dataset = train_dataset.remove_columns(['idx'])\n"
      ],
      "metadata": {
        "id": "0xTk6bx3kzvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Use a base model\n",
        "embedding_model = SentenceTransformer('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOZb_qA2kUOC",
        "outputId": "3ebb067c-1b3c-44e9-8420-2211c8ec3d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import losses\n",
        "\n",
        "# Define loss, in this case it is softmax loss.\n",
        "train_loss = losses.SoftmaxLoss(\n",
        "    model=embedding_model,\n",
        "    sentence_embedding_dimension=embedding_model.get_sentence_embedding_dimension(),\n",
        "    num_labels=3\n",
        ")"
      ],
      "metadata": {
        "id": "I4fDiNUjkkjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "\n",
        "# Create an embedding similarity evaluator for STSB\n",
        "val_sts=load_dataset('glue', 'stsb', split='validation')\n",
        "evaluator = EmbeddingSimilarityEvaluator(\n",
        "    sentences1=val_sts['sentence1'],\n",
        "    sentences2=val_sts['sentence2'],\n",
        "    scores=[score/5 for score in val_sts['label']],\n",
        "    main_similarity='cosine'\n",
        ")\n"
      ],
      "metadata": {
        "id": "rmcWSLRomTta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
        "\n",
        "# Define training arguments\n",
        "\n",
        "args = SentenceTransformerTrainingArguments(\n",
        "    output_dir='base_embedding_model',\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    warmup_steps=100,\n",
        "    fp16=True,\n",
        "    eval_steps=100,\n",
        "    logging_steps=100,\n",
        ")"
      ],
      "metadata": {
        "id": "uYdR4VNjnjjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
        "\n",
        "# Train embedding Model\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=embedding_model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    loss=train_loss,\n",
        "    evaluator=evaluator)\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764,
          "referenced_widgets": [
            "c2cb9dd20fa748f092257e151de4a90d",
            "290ff546e4a64b9f9bb5d34a632cc02f",
            "a418dd09edb1431d896f2470917d49cf",
            "1f32d452e8ef4e0b8248d0771ff77051",
            "10d137e231274e53a0f9314023af97bf",
            "e2eab3f38bb94f91bc64e2010da754dd",
            "26e7e93b3ae8479b8bb0af8d88908b9c",
            "ddf8aae8a3184df49af0661013fc5b3e",
            "dbf7bbe9b87f48478bc878126e49cd76",
            "0e27ef2f283349dcbc8680f95cfa6fa5",
            "e88217e65b3d4c51a130a0b9fc662f7b"
          ]
        },
        "id": "C-46BOStpnln",
        "outputId": "62a54c3e-af86-4728-a725-ace1722c3b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2cb9dd20fa748f092257e151de4a90d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/content/wandb/offline-run-20251213_134916-mzbm06pc</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.data_collator:Column 'hypothesis' is at index 1, whereas a column with this name is usually expected at index 0. Note that the column order can be important for some losses, e.g. MultipleNegativesRankingLoss will always consider the first column as the anchor and the second as the positive, regardless of the dataset column names. Consider renaming the columns to match the expected order, e.g.:\n",
            "dataset = dataset.select_columns(['hypothesis', 'entailment', 'contradiction'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1563/1563 08:08, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.064600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.932300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.876300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.831100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.820200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.819900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.806000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.785200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.774300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.770200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.742000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.730900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.750100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.712100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.745100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1563, training_loss=0.8076587611105072, metrics={'train_runtime': 500.3632, 'train_samples_per_second': 99.927, 'train_steps_per_second': 3.124, 'total_flos': 0.0, 'train_loss': 0.8076587611105072, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our trained model\n",
        "evaluator(embedding_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L6kJquWqKjs",
        "outputId": "dea1f8fe-1eb9-4a95-e851-986fb25b3578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pearson_cosine': 0.5677151949583746, 'spearman_cosine': 0.6403511856854297}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mteb import MTEB\n",
        "\n",
        "# Choose evaluation tasks\n",
        "evaluation = MTEB(tasks=['Banking77Classification'])\n",
        "\n",
        "# Calculate results\n",
        "results = evaluation.run(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "Dkv75SLnqzI0",
        "outputId": "705a628c-5a26-4792-ab28-0206a32d3148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mteb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-917468144.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmteb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMTEB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Choose evaluation tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMTEB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Banking77Classification'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mteb'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring Cosine Similarity Loss"
      ],
      "metadata": {
        "id": "I4ApZEnxrXwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (neutral / contradition) = 0 and (entailment) = 1\n",
        "mapping = {2:0, 1:0, 0:1}\n",
        "train_dataset = Dataset.from_dict({\n",
        "    'sentence1': train_dataset['premise'],\n",
        "    'sentence2': train_dataset['hypothesis'],\n",
        "    'label': [float(mapping[label] for label in train_dataset['label'])]\n",
        "    })"
      ],
      "metadata": {
        "id": "etZteFZq-ZWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "\n",
        "# Create an embedding similarity evaluator for stsb\n",
        "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
        "evaluator = EmbeddingSimilarityEvaluator(\n",
        "    sentences1=val_sts['sentence1'],\n",
        "    sentences2=val_sts['sentence2'],\n",
        "    scores=[score/5 for score in val_sts['label']],\n",
        "    main_similarity='cosine'\n",
        ")"
      ],
      "metadata": {
        "id": "3Ix0HU4vCDZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import losses, SentenceTransformer\n",
        "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
        "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
        "\n",
        "# Define model\n",
        "embedding_model = SentenceTransformer('bert-base-uncased')\n",
        "\n",
        "# Loss Function\n",
        "train_loss = losses.CosineSimilarityLoss(model=embedding_model)\n",
        "\n",
        "# Define the training arguments\n",
        "args = SentenceTransformerTrainingArguments(\n",
        "    output_dir='cosineloss_embedding_model',\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    warmup_steps=100,\n",
        "    fp16=True,\n",
        "    eval_steps=100,\n",
        "    logging_steps=100)\n",
        "\n",
        "# Train model\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=embedding_model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    loss=train_loss,\n",
        "    evaluator=evaluator)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "U2tn2fCcC0vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our trained model\n",
        "evaluator(embedding_model)"
      ],
      "metadata": {
        "id": "0Bmh8EzxE6w-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring MNR Loss"
      ],
      "metadata": {
        "id": "9tLkwopeFsGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tqdm import tqdm\n",
        "from datasets import Dataset, load_dataset\n",
        "\n",
        "# Load MNLI dataset from GLUE\n",
        "mnli = load_dataset('glue', 'mnli', split='train').select(range(50_000))\n",
        "mnli = mnli.remove_columns('idx')\n",
        "mnli = mnli.filter(lambda x: True if x['label'] == 0 else False)\n",
        "\n",
        "# Prepare data and add a soft negative\n",
        "train_dataset = {'anchor': [], 'positive': [], 'negative': []}\n",
        "soft_negatives = mnli['hypothesis']\n",
        "random.shuffle(soft_negatives)\n",
        "for row, soft_negative in tqdm(zip(mnli, soft_negatives)):\n",
        "    train_dataset['anchor'].append(row['premise'])\n",
        "    train_dataset['positive'].append(row['hypothesis'])\n",
        "    train_dataset['negative'].append(soft_negative)\n",
        "train_dataset = Dataset.from_dict(train_dataset)\n"
      ],
      "metadata": {
        "id": "Mdk1yDrkFxfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "\n",
        "# Create an embedding similarity evaluator for stsb\n",
        "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
        "evaluator = EmbeddingSimilarityEvaluator(\n",
        "    sentences1=val_sts['sentence1'],\n",
        "    sentences2=val_sts['sentence2'],\n",
        "    scores=[score/5 for score in val_sts['label']],\n",
        "    main_similarity='cosine'\n",
        ")"
      ],
      "metadata": {
        "id": "W9hzjl7RIBeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import losses, SentenceTransformer\n",
        "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
        "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
        "\n",
        "# Define model\n",
        "embedding_model = SentenceTransformer('bert-base-uncased')\n",
        "\n",
        "# Loss Function\n",
        "train_loss = losses.MultipleNegativesRankingLoss(model=embedding_model)\n",
        "\n",
        "# Define the training arguments\n",
        "args = SentenceTransformerTrainingArguments(\n",
        "    output_dir='mnrloss_embedding_model',\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    warmup_steps=100,\n",
        "    fp16=True,\n",
        "    eval_steps=100,\n",
        "    logging_steps=100)\n",
        "\n",
        "# Train model\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=embedding_model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    loss=train_loss,\n",
        "    evaluator=evaluator)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "QavwUsHLYEFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our trained model\n",
        "evaluator(embedding_model)"
      ],
      "metadata": {
        "id": "1DQ5N3p2YylT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning an embedding model : Supervised Learning"
      ],
      "metadata": {
        "id": "SH3CSpT8ZPyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "\n",
        "# Load MNLI dataset from GLUE\n",
        "# 0 = entailment, 1 = neutral, 2 = contradiction\n",
        "\n",
        "train_dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
        "train_dataset = train_dataset.remove_columns(['idx'])\n",
        "\n",
        "# Create an embedding similarity evaluator for stsb\n",
        "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
        "\n",
        "evaluator = EmbeddingSimilarityEvaluator(\n",
        "    sentences1=val_sts['sentence1'],\n",
        "    sentences2=val_sts['sentence2'],\n",
        "    scores=[score/5 for score in val_sts['label']],\n",
        "    main_similarity='cosine'\n",
        ")"
      ],
      "metadata": {
        "id": "MHhraF8lZVg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import losses, SentenceTransformer\n",
        "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
        "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
        "\n",
        "# Define model\n",
        "embedding_model = SentenceTransformer('sentence_transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Loss Function\n",
        "train_loss = losses.MultipleNegativesRankingLoss(model=embedding_model)\n",
        "\n",
        "# Define the training arguments\n",
        "args = SentenceTransformerTrainingArguments(\n",
        "    output_dir='finetuned_embedding_model',\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    fp16=True,\n",
        "    warmup_steps=100,\n",
        "    eval_steps=100,\n",
        "    logging_steps=100\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=embedding_model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    loss=train_loss,\n",
        "    evaluator=evaluator\n",
        "    )\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "zJDgOMxSYTGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our trained model\n",
        "evaluator(embedding_model)"
      ],
      "metadata": {
        "id": "fDpTrduPZdt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmented SBERT : Finetuning embedding model with scarce labelled data"
      ],
      "metadata": {
        "id": "gx-wW-CBZzYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from datasets import Dataset, load_dataset\n",
        "from sentence_transformers import InputExample\n",
        "from sentence_transformers.datasets import NoDuplicatesDataLoader\n",
        "\n",
        "# Prepare a small set of 10000 documents for the cross-encoder\n",
        "dataset = load_dataset('glue', 'mnli', split='train').select(range(10_000))\n",
        "# 0 = entailment, 1 = neutral, 2 = contradiction\n",
        "mapping = {2:0, 1:0, 0:1}\n",
        "\n",
        "# Data loader\n",
        "gold_examples = [\n",
        "    InputExample(texts=[row['premise'], row['hypothesis']], label=mapping[row['label']])\n",
        "    for row in tqdm(dataset)\n",
        "]\n",
        "\n",
        "gold_dataloader = NoDuplicatesDataLoader(\n",
        "    gold_examples, batch_size=32\n",
        ")\n",
        "\n",
        "# Pandas DataFrame for easier data handling\n",
        "gold = pd.DataFrame(\n",
        "    {\n",
        "        \"sentence1\": dataset['premise'],\n",
        "        \"sentence2\": dataset['hypothesis'],\n",
        "        \"label\": [mapping[label] for label in dataset['label']]\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "RBK6LxyraCSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers.cross_encoder import CrossEncoder\n",
        "\n",
        "# Train a cross-encoder on the gold dataset\n",
        "cross_encoder = CrossEncoder('bert-base-uncased', num_labels=2)\n",
        "cross_encoder.fit(\n",
        "    train_dataloader=gold_dataloader,\n",
        "    epochs=1,\n",
        "    show_progress-bar=True,\n",
        "    warmup_steps=100,\n",
        "    use_amp=False\n",
        ")"
      ],
      "metadata": {
        "id": "VHyq_BpwdH7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the silver dataset by predicting labels with the cross-encoder\n",
        "silver = load_dataset('glue', 'mnli', split='train').select(range(10_000, 50_000))\n",
        "pairs = list(zip(silver['premise'], silver['hypothesis']))"
      ],
      "metadata": {
        "id": "nNNT0SOjd7-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Label the sentence pairs using our fine-tuned cross-encoder\n",
        "output = cross_encoder.predict(pairs, apply_softmax=True, show_progress_bar=True)\n",
        "silver = pd.DataFrame(\n",
        "    {\n",
        "        \"sentence1\": silver['premise'],\n",
        "        \"sentence2\": silver['hypothesis'],\n",
        "        \"label\": np.argmax(output, axis=1)\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "DW1xeq_Fe15r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine Gold + Silver\n",
        "\n",
        "data = pd.concat([gold, silver], ignore_index=True, axis=0)\n",
        "data = data.drop_duplicates(subset=['sentence1', 'sentence2'], keep='first')\n",
        "train_dataset = Dataset.from_pandas(data, preserve_index=False)"
      ],
      "metadata": {
        "id": "fabgeZLLfWiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
        "\n",
        "# Create an embedding similarity evaluator for stsb\n",
        "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
        "evaluator = EmbeddingSimilarityEvaluator(\n",
        "    sentences1=val_sts['sentence1'],\n",
        "    sentences2=val_sts['sentence2'],\n",
        "    scores=[score/5 for score in val_sts['label']],\n",
        "    main_similarity='cosine'\n",
        ")"
      ],
      "metadata": {
        "id": "JbMJZ-b4gDcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import losses, SentenceTransformer\n",
        "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
        "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
        "\n",
        "# Define model\n",
        "embedding_model = SentenceTransformer('bert-base-uncased')\n",
        "\n",
        "# Loss Function\n",
        "train_loss = losses.CosineSimilarityLoss(model=embedding_model)\n",
        "\n",
        "# Define the training arguments\n",
        "args = SentenceTransformerTrainingArguments(\n",
        "    output_dir='augmented_embedding_model',\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    warmup=100,\n",
        "    fp16=True,\n",
        "    eval_steps=100,\n",
        "    logging_steps=100\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=embedding_model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    loss=train_loss,\n",
        "    evaluator=evaluator\n",
        "    )\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "RjSb5OjUgZrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator(embedding_model)"
      ],
      "metadata": {
        "id": "D8uM4TWQhR68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unsupervised Learning : Transformer-Based Sequential Denoising Auto-Encoder"
      ],
      "metadata": {
        "id": "amCQF0Efha-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download additional tokenizer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset, Dataset\n",
        "from sentence_transformers.datasets import DenoisingAutoEncoderDataset\n",
        "\n",
        "# Create a flat list of sentences\n",
        "mnli = load_dataset('glue', 'mnli', split='train').select(range(25_000))\n",
        "flat_sentences = mnli['premise'] + mnli['hypothesis']\n",
        "\n",
        "# Add noise to our input data\n",
        "damaged_data = DenoisingAutoEncoderDataset(list(set(flat_sentences)))\n",
        "\n",
        "# Create dataset\n",
        "train_dataset = {'damaged_sentence' : [], 'original_sentence' : []}\n",
        "\n",
        "for data in tqdm(damaged_data):\n",
        "    train_dataset['damaged_sentence'].append(data.texts[0])\n",
        "    train_dataset['original_sentence'].append(data.texts[1])\n",
        "\n",
        "train_dataset = Dataset.from_dict(train_dataset)\n",
        "\n",
        "train_dataset[0]"
      ],
      "metadata": {
        "id": "oBvYyFpAH8Kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformrs import models, SentenceTransformer\n",
        "\n",
        "# Create your embedding model\n",
        "word_embedding_model = models.Transformer('bert-base-uncased')\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), 'cls')\n",
        "embedding_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ],
      "metadata": {
        "id": "9yC9HmoCLXQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import losses\n",
        "\n",
        "# Use the denoising autoencoder loss\n",
        "train_loss = losses.DenoisingAutoEncoderLoss(embedding_model, tie_encoder_decoder=True)\n",
        "train_loss.decoder = train_loss.decoder.to('cuda')"
      ],
      "metadata": {
        "id": "Fqiev-eLMB6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
        "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
        "\n",
        "# Define the training arguments\n",
        "args = SentenceTransformerTrainingArguments(\n",
        "    output_dir='tsdae_embedding_model',\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    fp16=True,\n",
        "    warmup_steps=100,\n",
        "    eval_steps=100,\n",
        "    logging_steps=100\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=embedding_model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    loss=train_loss,\n",
        "    evaluator=evaluator\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "qOvTUK6MMwWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our trained model\n",
        "evaluator(embedding_model)"
      ],
      "metadata": {
        "id": "TPRnIcWTNxrn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}