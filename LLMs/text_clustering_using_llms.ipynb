{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -U datasets"
      ],
      "metadata": {
        "id": "oH7o1FWSLMN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --upgrade transformers==4.41.2 sentence-transformers==2.2.2 gensim==4.3.2 accelerate==0.31.0 peft==0.11.1 numpy==1.26.4"
      ],
      "metadata": {
        "id": "f4WdzwFsi7st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import disable_caching\n",
        "disable_caching()"
      ],
      "metadata": {
        "id": "tbU3gdGvi9-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaHPN0Ksf7bV"
      },
      "outputs": [],
      "source": [
        "# Load data from hugging face\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"maartengr/arxiv_nlp\")[\"train\"]\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05228d69"
      },
      "source": [
        "# Uninstall scikit-learn and scipy to resolve potential version conflicts\n",
        "#!pip uninstall -y scikit-learn scipy\n",
        "\n",
        "# Reinstall sentence-transformers to get compatible versions of dependencies\n",
        "#!pip install --upgrade sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract metadata\n",
        "\n",
        "abstracts = dataset[\"Abstracts\"]\n",
        "titles = dataset[\"Titles\"]"
      ],
      "metadata": {
        "id": "N74gIr1WixXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abstract_list = list(abstracts)"
      ],
      "metadata": {
        "id": "764Q4Csqn7je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade sentence-transformers"
      ],
      "metadata": {
        "id": "uFUPNG3Fvb0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "embedding_model = SentenceTransformer('thenlper/gte-small')\n",
        "\n",
        "# Encode the abstracts using the SentenceTransformer model\n",
        "embeddings = embedding_model.encode(abstract_list, show_progress_bar=True)\n",
        "\n",
        "embeddings.shape"
      ],
      "metadata": {
        "id": "lJf-vhFKkIP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dimensionality Reduction"
      ],
      "metadata": {
        "id": "wdYeBTo5numr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from umap import UMAP\n",
        "\n",
        "# Reduce the dimensions of the embeddings from 384 dimensions to 5 dimensions\n",
        "umap_model = UMAP(n_components=5, metric='cosine', min_dist=0.0, random_state=42)\n",
        "reduced_embeddings = umap_model.fit_transform(embeddings)\n",
        "\n",
        "reduced_embeddings.shape"
      ],
      "metadata": {
        "id": "k9CIRDkmm_ZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering"
      ],
      "metadata": {
        "id": "1tdZs1shnzZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hdbscan import HDBSCAN\n",
        "\n",
        "# Fit the model and extract the clusters\n",
        "hdbscan_model = HDBSCAN(min_cluster_size=50, metric='euclidean', cluster_selection_method='eom').fit(reduced_embeddings)\n",
        "clusters = hdbscan_model.labels_\n",
        "\n",
        "# How many clusters did we generate\n",
        "print(len(set(clusters)))"
      ],
      "metadata": {
        "id": "0ssNf4alnzFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspecting the clusters"
      ],
      "metadata": {
        "id": "eIlAYr5cs07z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "h84IDwdCs4PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print first three douments in the cluster\n",
        "cluster = 0\n",
        "for index in np.where(clusters==cluster)[0][:3]:\n",
        "  print(abstract_list[index][:300] + \"...\\n\")"
      ],
      "metadata": {
        "id": "lCtjtAX-s76D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Reduce 384 dimensions to 2 dimensions for easier visualization\n",
        "reduced_embeddings = UMAP(n_components=2, metric='cosine', min_dist=0.0, random_state=42).fit_transform(embeddings)\n",
        "\n",
        "# Create dataframe\n",
        "df = pd.DataFrame(reduced_embeddings, columns=['x', 'y'])\n",
        "df['text'] = titles\n",
        "df['cluster'] = [str(c) for c in clusters]\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "2xTnp0q3vcjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select outliers and non-outliers (clusters)\n",
        "\n",
        "to_plot = df.loc[df.cluster != \"-1\", :]\n",
        "outliers = df.loc[df.cluster == \"-1\", :]"
      ],
      "metadata": {
        "id": "NV_uRcgpwCJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "xajb0l0bw3ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot outliers and non-outliers separately\n",
        "\n",
        "plt.scatter(outliers.x, outliers.y, alpha=0.05, s=2, c=\"grey\")\n",
        "plt.scatter(to_plot.x, to_plot.y, c=to_plot.cluster.astype(int), s=2, alpha=0.6, cmap=\"tab20b\")\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "XrufaHvtxTXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install bertopic"
      ],
      "metadata": {
        "id": "nqKAeDtcsTW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic"
      ],
      "metadata": {
        "id": "lnyuaLLDLz96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the BERTopic model using previously defined embedding model, umap and hdbscan_model\n",
        "\n",
        "topic_model = BERTopic(embedding_model=embedding_model, umap_model=umap_model, hdbscan_model=hdbscan_model, verbose=True).fit(abstract_list, embeddings)\n"
      ],
      "metadata": {
        "id": "GraO9F5YL_9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.get_topic_info()"
      ],
      "metadata": {
        "id": "JOrZMJRtNXuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.get_topic(0)"
      ],
      "metadata": {
        "id": "EK8H0mIKNe9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.find_topics(\"topic_modeling\")"
      ],
      "metadata": {
        "id": "WFqObXSRNmeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize topics and documents"
      ],
      "metadata": {
        "id": "mtEqwLW-ORFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = topic_model.visualize_documents(\n",
        "    list(titles),\n",
        "    reduced_embeddings=reduced_embeddings,\n",
        "    width=1200,\n",
        "    #projection=\"umap\",\n",
        "    hide_annotations=True\n",
        ")\n",
        "\n",
        "# Update fonts of legend for easier visualizations\n",
        "fig.update_layout(font=dict(size=16))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "9yBnATMzOWZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring various visualization techniques of BERTopic"
      ],
      "metadata": {
        "id": "LtkgJE9PWJoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing barchart with ranked keywords\n",
        "topic_model.visualize_barchart()"
      ],
      "metadata": {
        "id": "N4AB8Ql1WHwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize relationships between topics\n",
        "topic_model.visualize_heatmap(n_clusters=30)"
      ],
      "metadata": {
        "id": "lo2ImjlfzYgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the potential hierarchical structure of topics\n",
        "topic_model.visualize_hierarchy()"
      ],
      "metadata": {
        "id": "KoF_AX-Tzcxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize topics and hierarchical relationships\n",
        "topic_model.visualize_topics()"
      ],
      "metadata": {
        "id": "GBGEoxoIzcPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save original representations of BERTopic before applying re-ranking techniques\n",
        "from copy import deepcopy\n",
        "\n",
        "original_topics = deepcopy(topic_model.topic_representations_)"
      ],
      "metadata": {
        "id": "NnsIRPKxXo_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic.representation import KeyBERTInspired\n",
        "from bertopic.representation import MaximalMarginalRelevance\n",
        "from bertopic.representation import TextGeneration\n",
        "from bertopic.representation import OpenAI\n",
        "from transformers import pipeline\n",
        "import openai"
      ],
      "metadata": {
        "id": "7X5UxTUeaKOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Following is a wrapper that visualizes the differences in topic words with and without representation models\n",
        "def topic_differences(model, original_topics, nr_topics=5):\n",
        "  df = pd.DataFrame(columns=[\"Topic\", \"Original\", \"Updated\"])\n",
        "\n",
        "  for topic in range(nr_topics):\n",
        "    # Extract top 5 words per topic\n",
        "    og_words = \" | \".join(list(zip(*original_topics[topic][1][:5])))\n",
        "    new_words = \" | \".join(list(zip(*model.get_topic(topic)[0][:5])))\n",
        "    df.loc[len(df)] = [topic, og_words, new_words]\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "3g972ACLYNwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update our topic representations using KeyBERTInspired\n",
        "representation_model = KeyBERTInspired()\n",
        "topic_model.update_topics(abstracts, representation_model=representation_model)"
      ],
      "metadata": {
        "id": "5sKkuu77f1xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show topic differences\n",
        "topic_differences(topic_model, original_topics)"
      ],
      "metadata": {
        "id": "Q1M7L-07DdLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_topics\n"
      ],
      "metadata": {
        "id": "s9KfX-SUBSZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update our topic representaions to MaximalMaginalRelevance\n",
        "representation_model = MaximalMarginalRelevance()\n",
        "topic_model.update_topics(abstracts, representation_model=representation_model)\n",
        "\n",
        "# Show topic differences\n",
        "topic_differences(topic_model, original_topics)"
      ],
      "metadata": {
        "id": "jSH4UmQRhD56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using text generation model such as Flan-T5 for topic representations\n",
        "\n",
        "prompt = \"\"\" I have a topic that contains the following documents:\n",
        "[DOCUMENTS]\n",
        "\n",
        "The topic is described by the following keywords : '[KEYWORDS]'.\n",
        "\n",
        "Based on the documents and the keywords, what is this topic about?\"\"\"\n",
        "\n",
        "# Update our topic representations using Flan-T5\n",
        "generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")\n",
        "representation_model = TextGeneration(prompt=prompt, generator=generator, doc_length=50, tokenizer='whitespace')\n",
        "topic_model.update_topics(abstracts, representation_model=representation_model)\n",
        "\n",
        "# Show topic differences\n",
        "topic_differences(topic_model, original_topics)"
      ],
      "metadata": {
        "id": "Dw74SDwKhU3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using a large text generation model with more linguistic capabilities - GPT-3.5 for topic representations\n",
        "\n",
        "prompt = \"\"\" I have a topic that contains the following documents:\n",
        "[DOCUMENTS]\n",
        "\n",
        "The topic is described by the following keywords : '[KEYWORDS]'.\n",
        "\n",
        "Based on the information above, extract a short topic label in the following format:\n",
        "topic: <short topic label>\n",
        "\"\"\"\n",
        "\n",
        "# Update our topic representations using GPT-3.5\n",
        "client = openai.OpenAI(api_key=\"YOUR_KEY_HERE\")\n",
        "representation_model = OpenAI(prompt=prompt, client=client, model='gpt-3.5-turbo', exponential_backoff=True, chat=True)\n",
        "topic_model.update_topics(abstracts, representation_model=representation_model)\n",
        "\n",
        "# Show topic differences\n",
        "topic_differences(topic_model, original_topics)"
      ],
      "metadata": {
        "id": "-uLwHs6liu8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize topics and documents\n",
        "\n",
        "fig = topic_model.visualize_document_datamap(\n",
        "    titles,\n",
        "    topics=list(range(20)),\n",
        "    reduced_embeddings=reduced_embeddings,\n",
        "    width=1200,\n",
        "    label_font_size=11,\n",
        "    label_wrap_width=20,\n",
        "    use_medoids=True\n",
        ")"
      ],
      "metadata": {
        "id": "8S5Tx87ekR5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notes on BERTopic"
      ],
      "metadata": {
        "id": "vFb19HNFPEVh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3kKfiGllPHjS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}